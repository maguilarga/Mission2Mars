{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASA Mars News\n",
    "\n",
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# Read the Web Page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a Beautiful Soup object\n",
    "soup = bs(response.text, 'html.parser')\n",
    "\n",
    "# Search for Header list section to scrape first Title and sub head\n",
    "results = soup.find('div', class_=\"slide\")\n",
    "\n",
    "# Identify and return the teaser paragraph of the article\n",
    "news_p = results.find('div', class_=\"rollover_description_inner\").text.strip()\n",
    "\n",
    "# Identify and return title of listing\n",
    "news_title = results.find('div', class_=\"content_title\").a.text.strip()\n",
    "\n",
    "# create a dictionary and save info\n",
    "mars_news = {\n",
    "    \"Title\": news_title,\n",
    "    \"SubHead\": news_p\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPL Mars Space Images - Featured Image\n",
    "# Use splinter to navigate the site and find the image url for the current Featured Mars Image\n",
    "\n",
    "# Path to 'chromedriver.exe' file\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# Open the browser to the web site\n",
    "url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "site_url = url.split('/spaceimages')[0]\n",
    "browser.visit(url)\n",
    "\n",
    "# Read the page\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Navigate to full image page\n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "\n",
    "# Read the page\n",
    "html = browser.html\n",
    "# wait for the page to be fully loaded\n",
    "time.sleep(2)\n",
    "soup = bs(html, 'html.parser')\n",
    "# Navigate to more info page\n",
    "browser.click_link_by_partial_text('more info')\n",
    "\n",
    "# Read the page\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# find the image\n",
    "mars_image = soup.find('figure', class_=\"lede\").a['href']\n",
    "mars_image = f\"{site_url}{mars_image}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Weather\n",
    "# URL of page to be scraped\n",
    "url = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "# Read the Web Page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a Beautiful Soup object\n",
    "soup = bs(response.text, 'html.parser')\n",
    "\n",
    "# Search for Mars weather tweets\n",
    "mars_weather = soup.find('div', class_=\"js-tweet-text-container\").p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Facts (using pandas)\n",
    "# point to the site \n",
    "url = 'https://space-facts.com/mars/'\n",
    "\n",
    "# Use Panda's `read_html` to parse the url\n",
    "tables = pd.read_html(url)\n",
    "mars_facts_html = tables[1].rename(columns={0: \"Description\", 1: \"Value\"}). \\\n",
    "    to_html(bold_rows=True, border=2, index=False, classes=['table_fmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Hemispheres\n",
    "\n",
    "# # Path to 'chromedriver.exe' file\n",
    "# executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "# browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# Open the browser to the web site\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(url)\n",
    "\n",
    "# Read the first page\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Get a list of the hemisferes links\n",
    "hem_links = []\n",
    "all_hemis = soup.find_all('div', class_='description')\n",
    "\n",
    "for hemis in all_hemis:\n",
    "    hem_links.append(hemis.h3.text.strip())  \n",
    "\n",
    "# Create a list of dictionaries with the information of each hemisfere\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Navigate to each hemisfere to gather the required information\n",
    "for hem in hem_links:\n",
    "    \n",
    "    # Navigate to the category\n",
    "    browser.click_link_by_partial_text(hem)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "\n",
    "    # Gather title information\n",
    "    hem_url = soup.find('div', class_=\"downloads\").find('li').a['href']\n",
    "    \n",
    "    # All info in a dictionary and append to hemisferes list\n",
    "    hem_info = {\n",
    "        \"title\": hem.replace('Enhanced', '').strip(), \n",
    "        \"img_url\": hem_url\n",
    "    }\n",
    "    hemisphere_image_urls.append(hem_info)\n",
    "\n",
    "    # Go back to previous page and continue\n",
    "    browser.back()\n",
    "    \n",
    "# Close the browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_mars_dict = {\n",
    "    \"Mars_News\": mars_news,\n",
    "    \"Mars_Images\": mars_image,\n",
    "    \"Mars_Weather\": mars_weather,\n",
    "    \"Mars_Facts\": mars_facts_html,\n",
    "    \"Mars_Hem\": hemisphere_image_urls\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script --output \"scrape_mars.py\" mission_to_mars.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
